# Nupo AI - Enterprise RAG System

A complete **Retrieval-Augmented Generation (RAG)** system built for Nupo, featuring web scraping, vector search, and OpenAI integration with a user-friendly interface.

## ğŸ¯ Project Overview

This system provides intelligent customer support by:
- **Web scraping** company websites for up-to-date content
- **Semantic search** through vectorized documents using OpenAI embeddings
- **AI-powered responses** using GPT-4o-mini with company-specific context
- **User-friendly interface** for non-technical users

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Scraper   â”‚â”€â”€â”€â–¶â”‚  Vector Database â”‚â”€â”€â”€â–¶â”‚   Chat API      â”‚
â”‚   (Playwright)  â”‚    â”‚     (FAISS)      â”‚    â”‚   (FastAPI)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â–²                        â–²
                                â”‚                        â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ OpenAI Embeddingsâ”‚    â”‚   OpenAI GPT    â”‚
                       â”‚ text-embedding-3 â”‚    â”‚   gpt-4o-mini   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Key Features

### âœ… **Stable & Crash-Free**
- **OpenAI embeddings** (no local PyTorch crashes)
- **FAISS vector database** for fast semantic search
- **Persistent API key storage** with encryption
- **17ms average query response time**

### âœ… **Production-Ready UI**
- **Embedded HTML interface** at `http://127.0.0.1:8000`
- **Markdown rendering** (bold, links, lists)
- **Source citations** with clickable links
- **API key management** interface

### âœ… **Smart Content Processing**
- **2167+ documents** scraped from nupo.dk and nupo.co.uk
- **URL deduplication** and content cleaning
- **Semantic retrieval** of top 5 relevant documents
- **1000 characters per document** for context

### âœ… **Customizable AI Responses**
- **System prompt management** for brand voice
- **Formatting rules** (numbered lists, bold text)
- **Source linking** with document references
- **600 token responses** for comprehensive answers

## ğŸ“ Project Structure

```
nupo-ai/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraping/
â”‚   â”‚   â”œâ”€â”€ scraper.py              # Main web scraping logic
â”‚   â”‚   â”œâ”€â”€ url_utils.py            # URL normalization & deduplication
â”‚   â”‚   â””â”€â”€ content_processor.py    # Content cleaning & processing
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ embeddings.py           # OpenAI embedding generation
â”‚   â”‚   â”œâ”€â”€ vector_store.py         # FAISS vector database management
â”‚   â”‚   â”œâ”€â”€ retrieval.py            # Document retrieval & ranking
â”‚   â”‚   â”œâ”€â”€ prompt_manager.py       # System prompt management
â”‚   â”‚   â””â”€â”€ key_manager.py          # Encrypted API key storage
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ chat_api.py             # FastAPI server with embedded UI
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ scraped_content/            # Raw scraped content
â”‚   â”œâ”€â”€ vector_db/                  # FAISS index files
â”‚   â””â”€â”€ prompts/                    # System prompt templates
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ .key                        # Encryption key (auto-generated)
â”‚   â””â”€â”€ api_keys.json              # Encrypted API keys
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .env                           # Environment variables
â””â”€â”€ README.md                      # This file
```

## ğŸ› ï¸ Installation & Setup

### Prerequisites
- **Python 3.8+**
- **OpenAI API key**
- **Internet connection** for scraping

### 1. Clone Repository
```bash
git clone <repository-url>
cd nupo-ai
```

### 2. Create Virtual Environment
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Environment Setup
Create `.env` file:
```bash
# Optional - can be set via UI instead
OPENAI_API_KEY=your_openai_api_key_here
```

### 5. Run Initial Scraping (Optional)
```bash
python src/scraping/scraper.py
```

### 6. Start Server
```bash
source venv/bin/activate && source .env && python src/api/chat_api.py
```

### 7. Access Interface
Open browser to: `http://127.0.0.1:8000`

## ğŸ”§ Configuration

### System Prompts
Edit prompts in `src/rag/prompt_manager.py` or via the API:
- **Default**: General customer support tone
- **Brand-specific**: Customizable via prompt management

### Scraping Targets
Modify `src/scraping/scraper.py` to add new websites:
```python
base_urls = [
    "https://nupo.dk",
    "https://nupo.co.uk",
    # Add more URLs here
]
```

### Response Settings
Adjust in `src/api/chat_api.py`:
- **Document count**: Currently retrieves 5 documents
- **Content length**: 1000 characters per document
- **Response length**: 600 tokens max
- **Formatting rules**: Built into system prompt

## ğŸ” Security Features

### API Key Encryption
- **AES encryption** using `cryptography` library
- **File permissions**: 600 (owner read/write only)
- **Automatic key generation** on first run

### Data Storage
- **Local FAISS database** (no external dependencies)
- **Encrypted configuration** files
- **Environment variable** support

## ğŸ› Troubleshooting

### Common Issues

#### Server Won't Start (Port 8000 in use)
```bash
lsof -ti:8000 | xargs kill -9
```

#### API Key Not Found
1. Enter API key via web interface
2. Or set `OPENAI_API_KEY` in `.env` file

#### Empty Search Results
1. Run scraping: `python src/scraping/scraper.py`
2. Check vector database: `data/vector_db/` should contain files

#### JavaScript Console Errors
- Hard refresh browser (Ctrl+Shift+R)
- Check browser console for specific errors

### Performance Issues

#### Slow Responses
- **Normal**: 17ms for retrieval + 2-3s for OpenAI API
- **Check**: OpenAI API key validity and rate limits

#### Memory Usage
- **Vector DB**: ~200MB for 2000+ documents
- **No PyTorch**: Eliminates segmentation faults

## ğŸ”„ Development Workflow

### Adding New Features
1. **Scraping**: Modify `src/scraping/scraper.py`
2. **Retrieval**: Update `src/rag/retrieval.py`
3. **UI**: Edit HTML in `src/api/chat_api.py`
4. **Prompts**: Manage via `src/rag/prompt_manager.py`

### Testing Changes
```bash
# Kill existing server
lsof -ti:8000 | xargs kill -9

# Restart with changes
source venv/bin/activate && source .env && python src/api/chat_api.py
```

### Debugging
- **Server logs**: Check terminal output
- **Browser console**: F12 â†’ Console tab
- **API responses**: Check network tab in browser

## ğŸ“Š System Stats

### Current Performance
- **Documents**: 2167 scraped pages
- **Vector dimensions**: 1536 (OpenAI text-embedding-3-small)
- **Index size**: 1088 vectors in FAISS
- **Query speed**: 17ms average
- **Unique URLs**: 392 after deduplication

### Scalability
- **FAISS**: Handles millions of vectors
- **OpenAI**: Rate limited (check your plan)
- **Storage**: ~1GB per 10k documents

## ğŸš€ Production Deployment

### Recommended Setup
1. **Server**: Ubuntu 20.04+ with 4GB+ RAM
2. **Domain**: Point to your server IP
3. **SSL**: Use Let's Encrypt for HTTPS
4. **Process manager**: Use PM2 or systemd
5. **Reverse proxy**: Nginx for production

### Environment Variables
```bash
OPENAI_API_KEY=your_production_key
PORT=8000
HOST=0.0.0.0
DEBUG=false
```

## ğŸ”® Future Enhancements

### Planned Features
- [ ] **Multi-tenant architecture** for different clients
- [ ] **Advanced prompt management UI**
- [ ] **Analytics dashboard** for query tracking
- [ ] **A/B testing framework** for prompts
- [ ] **Supervised Fine-Tuning (SFT)** pipeline

### SFT Implementation (Future)
If you need custom model training:
1. **Collect training data** (1000+ examples)
2. **Hire ML engineer** ($120k-$200k annually)
3. **Training infrastructure** (GPU clusters)
4. **3-6 month timeline** for production-ready results

## ğŸ“ Technical Decisions

### Why OpenAI Embeddings?
- **Stability**: No segmentation faults (unlike sentence-transformers)
- **Quality**: Superior semantic understanding
- **Maintenance**: No local model management

### Why FAISS?
- **Speed**: Millisecond search times
- **Scalability**: Handles millions of vectors
- **Local**: No external database dependencies

### Why FastAPI?
- **Performance**: Async support for concurrent requests
- **Documentation**: Automatic API docs
- **Integration**: Easy OpenAI API integration

## ğŸ¤ Contributing

### Code Style
- **Python**: Follow PEP 8
- **Logging**: Use loguru for consistent logging
- **Error handling**: Graceful degradation
- **Documentation**: Update README for major changes

### Git Workflow
```bash
git checkout -b feature/your-feature
git commit -m "Add: your feature description"
git push origin feature/your-feature
```

## ğŸ“„ License

Private repository - All rights reserved.

---

## ğŸ†˜ Quick Start Checklist

- [ ] Clone repository
- [ ] Create virtual environment
- [ ] Install requirements
- [ ] Set OpenAI API key (via UI or .env)
- [ ] Run scraping (optional - data included)
- [ ] Start server: `python src/api/chat_api.py`
- [ ] Test at `http://127.0.0.1:8000`

**Need help?** Check the troubleshooting section or review server logs for specific error messages.